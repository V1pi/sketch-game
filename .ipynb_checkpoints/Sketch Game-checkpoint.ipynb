{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import struct\n",
    "from struct import unpack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cairocffi as cairo\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import model_from_json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
    "    \"\"\"\n",
    "    padding and line_diameter are relative to the original 256x256 image.\n",
    "    \"\"\"\n",
    "    \n",
    "    original_side = 256.\n",
    "    \n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
    "    ctx = cairo.Context(surface)\n",
    "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
    "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
    "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
    "    ctx.set_line_width(line_diameter)\n",
    "\n",
    "    # scale to match the new size\n",
    "    # add padding at the edges for the line_diameter\n",
    "    # and add additional padding to account for antialiasing\n",
    "    total_padding = padding * 2. + line_diameter\n",
    "    new_scale = float(side) / float(original_side + total_padding)\n",
    "    ctx.scale(new_scale, new_scale)\n",
    "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
    "\n",
    "    raster_images = []\n",
    "    for vector_image in vector_images:\n",
    "        # clear background\n",
    "        ctx.set_source_rgb(*bg_color)\n",
    "        ctx.paint()\n",
    "        \n",
    "        bbox = np.hstack(vector_image).max(axis=1)\n",
    "        offset = ((original_side, original_side) - bbox) / 2.\n",
    "        offset = offset.reshape(-1,1)\n",
    "        centered = [stroke + offset for stroke in vector_image]\n",
    "    \n",
    "        # draw strokes, this is the most cpu-intensive part\n",
    "        ctx.set_source_rgb(*fg_color)        \n",
    "        for xv, yv in centered:\n",
    "            ctx.move_to(xv[0], yv[0])\n",
    "            for x, y in zip(xv, yv):\n",
    "                ctx.line_to(x, y)\n",
    "            ctx.stroke()\n",
    "\n",
    "        data = surface.get_data()\n",
    "        raster_image = np.copy(np.asarray(data)[::4])\n",
    "        raster_images.append(raster_image)\n",
    "    \n",
    "    return raster_images\n",
    "\n",
    "def unpack_drawing(file_handle, label):\n",
    "    key_id, = unpack('Q', file_handle.read(8))\n",
    "    countrycode, = unpack('2s', file_handle.read(2))\n",
    "    recognized, = unpack('b', file_handle.read(1))\n",
    "    timestamp, = unpack('I', file_handle.read(4))\n",
    "    n_strokes, = unpack('H', file_handle.read(2))\n",
    "    image = []\n",
    "    for i in range(n_strokes):\n",
    "        n_points, = unpack('H', file_handle.read(2))\n",
    "        fmt = str(n_points) + 'B'\n",
    "        x = unpack(fmt, file_handle.read(n_points))\n",
    "        y = unpack(fmt, file_handle.read(n_points))\n",
    "        image.append((x, y))\n",
    "    return (image, label)\n",
    "\n",
    "\n",
    "def unpack_drawings(filename, label):\n",
    "    with open(filename, 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                yield unpack_drawing(f, label)\n",
    "            except struct.error as e:\n",
    "                break\n",
    "\n",
    "def unpack_draw(filename, label):\n",
    "    list_drawing = []\n",
    "    for drawing in unpack_drawings('data/' + filename + '.bin', label):\n",
    "        # do something with the drawing\n",
    "        list_drawing.append(drawing)\n",
    "    \n",
    "    return list_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "classes = ['axe', 'basketball', 'baseball bat']\n",
    "data_list = unpack_draw('axe', 0)\n",
    "data_list.extend(unpack_draw('basketball', 1))\n",
    "data_list.extend(unpack_draw('baseball bat', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = shuffle(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = np.array(vector_to_raster(list(map(lambda x: x[0], data_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = np.array(list(map(lambda x: np.reshape(np.array(x/255), (28,28,1)), data_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7feb09efe320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(data_image[0], (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = np.array(list(map(lambda x: tf.keras.utils.to_categorical(x[1], num_classes=n_classes), data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_train, draw_test, label_train, label_test = \\\n",
    "train_test_split(data_image, data_labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267206, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(28, 28, 1), strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name='model1'):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"{0}.json\".format(name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"{0}.h5\".format(name))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "def load_model(name='model1'):\n",
    "    json_file = open(\"{0}.json\".format(name), 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"{0}.h5\".format(name))\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "def optimizer():\n",
    "    return SGD(lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Physical devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4025a8990b1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_virtual_device_configuration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVirtualDeviceConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2736\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/config.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[0;34m(device, enable)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRuntime\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m   \"\"\"\n\u001b[0;32m--> 494\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[0;34m(self, dev, enable)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m       raise RuntimeError(\n\u001b[0;32m-> 1241\u001b[0;31m           \"Physical devices cannot be modified after being initialized\")\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memory_growth_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Physical devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "model_name = 'model1'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2736)])\n",
    "model = create_model()\n",
    "model.compile(optimizer=optimizer(),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy']\n",
    "          )\n",
    "model.fit(draw_train, label_train, batch_size=batch_size, epochs=1, validation_data=(draw_test,label_test),verbose=1)\n",
    "model.summary()\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
