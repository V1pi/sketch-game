{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import struct\n",
    "from struct import unpack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cairocffi as cairo\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import model_from_json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
    "    \"\"\"\n",
    "    padding and line_diameter are relative to the original 256x256 image.\n",
    "    \"\"\"\n",
    "    \n",
    "    original_side = 256.\n",
    "    \n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
    "    ctx = cairo.Context(surface)\n",
    "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
    "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
    "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
    "    ctx.set_line_width(line_diameter)\n",
    "\n",
    "    # scale to match the new size\n",
    "    # add padding at the edges for the line_diameter\n",
    "    # and add additional padding to account for antialiasing\n",
    "    total_padding = padding * 2. + line_diameter\n",
    "    new_scale = float(side) / float(original_side + total_padding)\n",
    "    ctx.scale(new_scale, new_scale)\n",
    "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
    "\n",
    "    raster_images = []\n",
    "    for vector_image in vector_images:\n",
    "        # clear background\n",
    "        ctx.set_source_rgb(*bg_color)\n",
    "        ctx.paint()\n",
    "        \n",
    "        bbox = np.hstack(vector_image).max(axis=1)\n",
    "        offset = ((original_side, original_side) - bbox) / 2.\n",
    "        offset = offset.reshape(-1,1)\n",
    "        centered = [stroke + offset for stroke in vector_image]\n",
    "    \n",
    "        # draw strokes, this is the most cpu-intensive part\n",
    "        ctx.set_source_rgb(*fg_color)        \n",
    "        for xv, yv in centered:\n",
    "            ctx.move_to(xv[0], yv[0])\n",
    "            for x, y in zip(xv, yv):\n",
    "                ctx.line_to(x, y)\n",
    "            ctx.stroke()\n",
    "\n",
    "        data = surface.get_data()\n",
    "        raster_image = np.copy(np.asarray(data)[::4])\n",
    "        raster_images.append(raster_image)\n",
    "    \n",
    "    return raster_images\n",
    "\n",
    "def unpack_drawing(file_handle, label):\n",
    "    key_id, = unpack('Q', file_handle.read(8))\n",
    "    countrycode, = unpack('2s', file_handle.read(2))\n",
    "    recognized, = unpack('b', file_handle.read(1))\n",
    "    timestamp, = unpack('I', file_handle.read(4))\n",
    "    n_strokes, = unpack('H', file_handle.read(2))\n",
    "    image = []\n",
    "    for i in range(n_strokes):\n",
    "        n_points, = unpack('H', file_handle.read(2))\n",
    "        fmt = str(n_points) + 'B'\n",
    "        x = unpack(fmt, file_handle.read(n_points))\n",
    "        y = unpack(fmt, file_handle.read(n_points))\n",
    "        image.append((x, y))\n",
    "    return (image, label)\n",
    "\n",
    "\n",
    "def unpack_drawings(filename, label):\n",
    "    with open(filename, 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                yield unpack_drawing(f, label)\n",
    "            except struct.error as e:\n",
    "                break\n",
    "\n",
    "def unpack_draw(filename, label):\n",
    "    list_drawing = []\n",
    "    for drawing in unpack_drawings('data/' + filename + '.bin', label):\n",
    "        # do something with the drawing\n",
    "        list_drawing.append(drawing)\n",
    "    \n",
    "    return list_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "classes = ['axe', 'basketball', 'baseball bat']\n",
    "data_list = unpack_draw('axe', 0)\n",
    "data_list.extend(unpack_draw('basketball', 1))\n",
    "data_list.extend(unpack_draw('baseball bat', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = shuffle(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = np.array(vector_to_raster(list(map(lambda x: x[0], data_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = np.array(list(map(lambda x: np.reshape(np.array(x/255), (28,28,1)), data_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f37cf83e358>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(data_image[0], (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = np.array(list(map(lambda x: tf.keras.utils.to_categorical(x[1], num_classes=n_classes), data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_train, draw_test, label_train, label_test = \\\n",
    "train_test_split(data_image, data_labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267206, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(28, 28, 1), strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name='model1'):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"{0}.json\".format(name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"{0}.h5\".format(name))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "def load_model(name='model1'):\n",
    "    json_file = open(\"{0}.json\".format(name), 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"{0}.h5\".format(name))\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "def optimizer():\n",
    "    return SGD(lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model1'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2736)])\n",
    "model = create_model()\n",
    "model.compile(optimizer=optimizer(),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy']\n",
    "          )\n",
    "model.fit(draw_train, label_train, batch_size=batch_size, epochs=1, validation_data=(draw_test,label_test),verbose=1)\n",
    "model.summary()\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
