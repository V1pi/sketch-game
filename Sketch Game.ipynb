{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "import struct\n",
    "from struct import unpack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import cairocffi as cairo\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import model_from_json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_raster(vector_images, side=28, line_diameter=16, padding=16, bg_color=(0,0,0), fg_color=(1,1,1)):\n",
    "    \"\"\"\n",
    "    padding and line_diameter are relative to the original 256x256 image.\n",
    "    \"\"\"\n",
    "    \n",
    "    original_side = 256.\n",
    "    \n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n",
    "    ctx = cairo.Context(surface)\n",
    "    ctx.set_antialias(cairo.ANTIALIAS_BEST)\n",
    "    ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n",
    "    ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n",
    "    ctx.set_line_width(line_diameter)\n",
    "\n",
    "    # scale to match the new size\n",
    "    # add padding at the edges for the line_diameter\n",
    "    # and add additional padding to account for antialiasing\n",
    "    total_padding = padding * 2. + line_diameter\n",
    "    new_scale = float(side) / float(original_side + total_padding)\n",
    "    ctx.scale(new_scale, new_scale)\n",
    "    ctx.translate(total_padding / 2., total_padding / 2.)\n",
    "\n",
    "    raster_images = []\n",
    "    for vector_image in vector_images:\n",
    "        # clear background\n",
    "        ctx.set_source_rgb(*bg_color)\n",
    "        ctx.paint()\n",
    "        \n",
    "        bbox = np.hstack(vector_image).max(axis=1)\n",
    "        offset = ((original_side, original_side) - bbox) / 2.\n",
    "        offset = offset.reshape(-1,1)\n",
    "        centered = [stroke + offset for stroke in vector_image]\n",
    "    \n",
    "        # draw strokes, this is the most cpu-intensive part\n",
    "        ctx.set_source_rgb(*fg_color)        \n",
    "        for xv, yv in centered:\n",
    "            ctx.move_to(xv[0], yv[0])\n",
    "            for x, y in zip(xv, yv):\n",
    "                ctx.line_to(x, y)\n",
    "            ctx.stroke()\n",
    "\n",
    "        data = surface.get_data()\n",
    "        raster_image = np.copy(np.asarray(data)[::4])\n",
    "        raster_images.append(raster_image)\n",
    "    \n",
    "    return raster_images\n",
    "\n",
    "def unpack_drawing(file_handle, label):\n",
    "    key_id, = unpack('Q', file_handle.read(8))\n",
    "    countrycode, = unpack('2s', file_handle.read(2))\n",
    "    recognized, = unpack('b', file_handle.read(1))\n",
    "    timestamp, = unpack('I', file_handle.read(4))\n",
    "    n_strokes, = unpack('H', file_handle.read(2))\n",
    "    image = []\n",
    "    for i in range(n_strokes):\n",
    "        n_points, = unpack('H', file_handle.read(2))\n",
    "        fmt = str(n_points) + 'B'\n",
    "        x = unpack(fmt, file_handle.read(n_points))\n",
    "        y = unpack(fmt, file_handle.read(n_points))\n",
    "        image.append((x, y))\n",
    "    return (image, label)\n",
    "\n",
    "\n",
    "def unpack_drawings(filename, label):\n",
    "    with open(filename, 'rb') as f:\n",
    "        while True:\n",
    "            try:\n",
    "                yield unpack_drawing(f, label)\n",
    "            except struct.error as e:\n",
    "                break\n",
    "\n",
    "def unpack_draw(filename, label):\n",
    "    list_drawing = []\n",
    "    for drawing in unpack_drawings('data/' + filename + '.bin', label):\n",
    "        # do something with the drawing\n",
    "        list_drawing.append(drawing)\n",
    "    \n",
    "    return list_drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "classes = ['axe', 'basketball', 'baseball bat']\n",
    "data_list = unpack_draw('axe', 0)\n",
    "data_list.extend(unpack_draw('basketball', 1))\n",
    "data_list.extend(unpack_draw('baseball bat', 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = shuffle(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = np.array(vector_to_raster(list(map(lambda x: x[0], data_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_image = np.array(list(map(lambda x: np.reshape(np.array(x/255), (28,28,1)), data_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff429dbf0b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(data_image[0], (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels = np.array(list(map(lambda x: tf.keras.utils.to_categorical(x[1], num_classes=n_classes), data_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_train, draw_test, label_train, label_test = \\\n",
    "train_test_split(data_image, data_labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267206, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), input_shape=(28, 28, 1), strides=1, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(2, 2), strides=1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name='model1'):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"{0}.json\".format(name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"{0}.h5\".format(name))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "def load_model(name='model1'):\n",
    "    json_file = open(\"{0}.json\".format(name), 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"{0}.h5\".format(name))\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "def optimizer():\n",
    "    return SGD(lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Train on 267206 samples, validate on 114518 samples\n",
      "Epoch 1/5\n",
      "267206/267206 [==============================] - 40s 148us/sample - loss: 0.3101 - accuracy: 0.9003 - val_loss: 0.2562 - val_accuracy: 0.9144\n",
      "Epoch 2/5\n",
      "267206/267206 [==============================] - 39s 147us/sample - loss: 0.2718 - accuracy: 0.9121 - val_loss: 0.2312 - val_accuracy: 0.9248\n",
      "Epoch 3/5\n",
      "267206/267206 [==============================] - 39s 147us/sample - loss: 0.2520 - accuracy: 0.9171 - val_loss: 0.2229 - val_accuracy: 0.9236\n",
      "Epoch 4/5\n",
      "267206/267206 [==============================] - 39s 148us/sample - loss: 0.2372 - accuracy: 0.9214 - val_loss: 0.2269 - val_accuracy: 0.9253\n",
      "Epoch 5/5\n",
      "267206/267206 [==============================] - 40s 148us/sample - loss: 0.2245 - accuracy: 0.9256 - val_loss: 0.2724 - val_accuracy: 0.9112\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 64)          32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 32)          4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 212,739\n",
      "Trainable params: 212,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model1'\n",
    "try:\n",
    "    model = load_model(model_name)\n",
    "except:\n",
    "    model = create_model()\n",
    "model.compile(optimizer=optimizer(),\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy']\n",
    "          )\n",
    "model.fit(draw_train, label_train, batch_size=batch_size, epochs=5, validation_data=(draw_test,label_test),verbose=1)\n",
    "model.summary()\n",
    "save_model(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
